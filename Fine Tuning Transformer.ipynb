{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_5laSqpFZ8G"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers -U\n",
        "!pip install accelerate -U\n",
        "!pip install trl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "BkPXgdlfGZqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "DATASET_NAME = \"mlabonne/guanaco-llama2-1k\"\n",
        "dataset = load_dataset(DATASET_NAME)"
      ],
      "metadata": {
        "id": "FTpE69MwGu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "BtvIl0ZqHWcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = dataset[\"train\"]\n",
        "print(training_dataset)"
      ],
      "metadata": {
        "id": "1bciuf0mHnUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_number = torch.randint(0, 1000, (1,)).item()\n",
        "print(f\"Random number: {random_number}\")\n",
        "training_dataset[random_number]"
      ],
      "metadata": {
        "id": "CAllJyYQHscB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilgpt2\"\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# load in the model, use caching, load in tokenizer, set token padding\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
        "model.config.use_cache = True\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code = True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# configure generator\n",
        "generation_configuration = model.generation_config\n",
        "generation_configuration.pad_token_id = tokenizer.eos_token_id\n",
        "generation_configuration.eos_token_id = tokenizer.eos_token_id\n",
        "generation_configuration.max_new_tokens = 1024\n",
        "generation_configuration.temperature = .7 # scales down output (softmax probabilities)\n",
        "generation_configuration.top_p = .9\n",
        "generation_configuration.top_k = 20\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rOHI2WVOJwJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt):\n",
        "  encoded = tokenizer.encode(prompt, add_special_tokens = True, return_tensors='pt').to(device)\n",
        "  out = model.generate(input_ids = encoded, repetition_penalty = 1.2, do_sample = True) #multinomial sampling\n",
        "  string_decoded = tokenizer.decode(out[0].tolist(), clean_up_tokenization_spaces =True)\n",
        "  print(string_decoded)"
      ],
      "metadata": {
        "id": "PEQAFL3303sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate('this is')"
      ],
      "metadata": {
        "id": "-uo7eg1E2ane"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate('how are you?')"
      ],
      "metadata": {
        "id": "xZyjUFns2clc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# set up your training arguments\n",
        "training_args = SFTConfig(\n",
        "gradient_accumulation_steps=1,\n",
        "num_train_epochs=5,\n",
        "learning_rate=5e-5,\n",
        "fp16=True,\n",
        "output_dir=\"logs\",\n",
        "lr_scheduler_type=\"cosine\",\n",
        "warmup_ratio=0.05,\n",
        "group_by_length=True,\n",
        "max_length=512\n",
        "\n",
        ")\n",
        "\n",
        "# initialize the SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=training_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_args\n",
        ")"
      ],
      "metadata": {
        "id": "fTbUuAwX2fyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_configuration.do_sample = True\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "d8nFuw317zXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate(prompt):\n",
        "    # Wrap the prompt in the tags the model saw during training\n",
        "    formatted_prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
        "\n",
        "    encoded = tokenizer.encode(formatted_prompt, add_special_tokens=True, return_tensors='pt').to(model.device)\n",
        "\n",
        "    # Lower repetition_penalty; 2.0 is too aggressive and causes \"garbage\" output\n",
        "    out = model.generate(\n",
        "        input_ids=encoded,\n",
        "        repetition_penalty=1.1,\n",
        "        do_sample=True,\n",
        "        max_new_tokens=100\n",
        "    )\n",
        "\n",
        "    string_decoded = tokenizer.decode(out[0], skip_special_tokens=False)\n",
        "    print(string_decoded)"
      ],
      "metadata": {
        "id": "tDMnutCBNibo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate('What is your name?')"
      ],
      "metadata": {
        "id": "BZe-x6rs81dH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}